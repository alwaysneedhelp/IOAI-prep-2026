{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU","kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":129044,"databundleVersionId":15482057,"sourceType":"competition"}],"dockerImageVersionId":31260,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/shokhjahonisroilov/radar-best-score?scriptVersionId=295650978\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"import os\nos.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-02T08:41:21.589814Z","iopub.execute_input":"2026-02-02T08:41:21.590648Z","iopub.status.idle":"2026-02-02T08:41:21.594574Z","shell.execute_reply.started":"2026-02-02T08:41:21.590611Z","shell.execute_reply":"2026-02-02T08:41:21.59392Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport random\nfrom sklearn.model_selection import train_test_split\nimport torch.nn.functional as F\nfrom collections import Counter\nDATASET = '/kaggle/input/radar-ioai-2025'\nDATA_PATH = f'{DATASET}/training_set/training_set'\nTEST_DATA_PATH = f'{DATASET}/test_set/test_set'\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'","metadata":{"id":"14816054-3e25-4e51-9ffc-333564ffb3d6","trusted":true,"execution":{"iopub.status.busy":"2026-02-02T08:41:21.596141Z","iopub.execute_input":"2026-02-02T08:41:21.596702Z","iopub.status.idle":"2026-02-02T08:41:21.60879Z","shell.execute_reply.started":"2026-02-02T08:41:21.596677Z","shell.execute_reply":"2026-02-02T08:41:21.608101Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"seed = 42\nrandom.seed(seed)\nos.environ[\"PYTHONHASHSEED\"] = str(seed)\nnp.random.seed(seed)\ntorch.manual_seed(seed)\ntorch.cuda.manual_seed(seed)\ntorch.cuda.manual_seed_all(seed)\ntorch.backends.cudnn.deterministic = True\ntorch.backends.cudnn.benchmark = False","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-02T08:41:21.6098Z","iopub.execute_input":"2026-02-02T08:41:21.610127Z","iopub.status.idle":"2026-02-02T08:41:21.624026Z","shell.execute_reply.started":"2026-02-02T08:41:21.610099Z","shell.execute_reply":"2026-02-02T08:41:21.623345Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class CustomDataset(torch.utils.data.Dataset):\n    def __init__(self, file_paths):\n        self.file_paths = file_paths\n        self.static_idx = torch.tensor([0,2,4])\n        self.dynamic_idx = torch.tensor([1,3,5])\n\n\n    def __len__(self):\n        return len(self.file_paths)\n\n    def __getitem__(self, idx):\n        data = torch.load(self.file_paths[idx])\n\n        imgs_in  = data[:6].float()                 # [6, H, W] in original interleaved order\n        static3  = imgs_in.index_select(0, self.static_idx)   # [3, H, W]\n        dynamic3 = imgs_in.index_select(0, self.dynamic_idx)  # [3, H, W]\n        images   = torch.cat([static3, dynamic3], dim=0)\n\n        labels = data[6]\n\n        images = images.float()\n        labels = labels.long()\n\n        return images, labels\n\nclass TrainDataset(CustomDataset):\n    def __getitem__(self, idx):\n        images, labels = super().__getitem__(idx)\n\n        if random.random() < 0.5:\n            images[0] = images[0].flip(-1)\n            images[1] = images[1].flip(-1)\n            labels = labels.flip(-1)\n\n        return images, labels\n\nfile_paths = [f'{DATA_PATH}/{file}' for file in os.listdir(DATA_PATH) if file.endswith('.mat.pt')]\n\ntrain_dataset = TrainDataset(file_paths=file_paths)\n\ntrain_loader = torch.utils.data.DataLoader(\n    dataset = train_dataset,\n    shuffle = True,\n    batch_size = 8,\n    num_workers = 2,\n    drop_last = True,\n    pin_memory = True\n)","metadata":{"id":"e5bc0e06-1dbb-490a-bb3d-81d2a104cb88","trusted":true,"execution":{"iopub.status.busy":"2026-02-02T08:41:21.637819Z","iopub.execute_input":"2026-02-02T08:41:21.638092Z","iopub.status.idle":"2026-02-02T08:41:21.648577Z","shell.execute_reply.started":"2026-02-02T08:41:21.63807Z","shell.execute_reply":"2026-02-02T08:41:21.647892Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"file_paths","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-02T08:41:21.650065Z","iopub.execute_input":"2026-02-02T08:41:21.650371Z","iopub.status.idle":"2026-02-02T08:41:21.666009Z","shell.execute_reply.started":"2026-02-02T08:41:21.650343Z","shell.execute_reply":"2026-02-02T08:41:21.665354Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class DoubleConv(nn.Module):\n    def __init__(self, in_channels, out_channels):\n        super().__init__()\n        self.s = nn.Sequential(\n            nn.Conv2d(in_channels, out_channels, kernel_size= 3, padding='same'),\n            nn.BatchNorm2d(out_channels),\n            nn.GELU(),\n            nn.Dropout2d(0.3),\n            nn.Conv2d(out_channels, out_channels, kernel_size= 3, padding='same'),\n            nn.BatchNorm2d(out_channels),\n            nn.GELU(),\n        )\n    def forward(self, x):\n        return self.s(x)","metadata":{"id":"04e77b59-eda7-4e2f-8c0c-4750df01c190","trusted":true,"execution":{"iopub.status.busy":"2026-02-02T08:41:21.66673Z","iopub.execute_input":"2026-02-02T08:41:21.667026Z","iopub.status.idle":"2026-02-02T08:41:21.676298Z","shell.execute_reply.started":"2026-02-02T08:41:21.667004Z","shell.execute_reply":"2026-02-02T08:41:21.675611Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class ResBlock2d(nn.Module):\n  def __init__(self, in_channels, out_channels,res_scale=1.0):\n    super().__init__()\n    self.proj = nn.Conv2d(in_channels, out_channels, 1, bias=False)\n    self.res_scale = res_scale\n\n    self.block = DoubleConv(in_channels, out_channels)\n\n  def forward(self, x):\n    y = self.block(x)\n    s = self.proj(x)\n    return F.relu(s + self.res_scale * y, inplace=True)","metadata":{"id":"IGtwce47P7YS","trusted":true,"execution":{"iopub.status.busy":"2026-02-02T08:41:21.677206Z","iopub.execute_input":"2026-02-02T08:41:21.677462Z","iopub.status.idle":"2026-02-02T08:41:21.68756Z","shell.execute_reply.started":"2026-02-02T08:41:21.677431Z","shell.execute_reply":"2026-02-02T08:41:21.686812Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class Encode(nn.Module):\n    def __init__(self, in_channels, out_channels):\n        super().__init__()\n        self.conv = ResBlock2d(in_channels, out_channels)\n        self.pool = nn.MaxPool2d(2)\n        self.dropout = nn.Dropout2d(0.3)\n    def forward(self, x):\n        x = self.conv(x)\n        p = self.pool(x)\n        p = self.dropout(p)\n        return x, p","metadata":{"id":"b090e952-5555-4cbd-8811-492bcd805af0","trusted":true,"execution":{"iopub.status.busy":"2026-02-02T08:41:21.691758Z","iopub.execute_input":"2026-02-02T08:41:21.692367Z","iopub.status.idle":"2026-02-02T08:41:21.700721Z","shell.execute_reply.started":"2026-02-02T08:41:21.692339Z","shell.execute_reply":"2026-02-02T08:41:21.699984Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class AttentionGate(nn.Module):\n    def __init__(self, F_g, F_l, F_int):\n        super().__init__()\n        self.W_g = nn.Sequential(\n            nn.Conv2d(F_g, F_int, kernel_size=1, stride=1, padding=0, bias=True),\n            nn.BatchNorm2d(F_int)\n        )\n        self.W_x = nn.Sequential(\n            nn.Conv2d(F_l, F_int, kernel_size=1, stride=1, padding=0, bias=True),\n            nn.BatchNorm2d(F_int)\n        )\n        self.psi = nn.Sequential(\n            nn.Conv2d(F_int, 1, kernel_size=1, stride=1, padding=0, bias=True),\n            nn.BatchNorm2d(1),\n            nn.Sigmoid()\n        )\n        self.relu = nn.ReLU(inplace=True)\n\n    def forward(self, g, x):  # g = decoder feature, x = encoder skip feature\n        g1 = self.W_g(g)\n        x1 = self.W_x(x)\n        psi = self.relu(g1 + x1)\n        psi = self.psi(psi)\n        return x * psi  # element-wise gating\n","metadata":{"id":"YS3_ZAhGNCQi","trusted":true,"execution":{"iopub.status.busy":"2026-02-02T08:41:21.702071Z","iopub.execute_input":"2026-02-02T08:41:21.702346Z","iopub.status.idle":"2026-02-02T08:41:21.712393Z","shell.execute_reply.started":"2026-02-02T08:41:21.702324Z","shell.execute_reply":"2026-02-02T08:41:21.711828Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class Decode(nn.Module):\n    def __init__(self, in_channels, skip, out_channels, pad):\n        super().__init__()\n        # F_g must be out_channels, not in_channels\n        self.attn = AttentionGate(F_g=out_channels, F_l=skip, F_int=skip // 2)\n\n        self.unpool = nn.ConvTranspose2d(in_channels, out_channels, kernel_size=2, stride=2, output_padding=pad)\n        self.dropout = nn.Dropout2d(0.3)\n        self.conv = ResBlock2d(out_channels + skip, out_channels)\n\n    def forward(self, x, skip):\n        x = self.unpool(x)\n        skip = self.attn(x, skip)\n        x = torch.cat([x, skip], dim=1)\n        x = self.dropout(x)\n        x = self.conv(x)\n        return x","metadata":{"id":"d89af8a0-853d-43e7-ab2a-2151d0648bde","trusted":true,"execution":{"iopub.status.busy":"2026-02-02T08:41:21.713394Z","iopub.execute_input":"2026-02-02T08:41:21.71365Z","iopub.status.idle":"2026-02-02T08:41:21.724567Z","shell.execute_reply.started":"2026-02-02T08:41:21.713621Z","shell.execute_reply":"2026-02-02T08:41:21.723884Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class DuoUNet(nn.Module):\n    def __init__(self, in_channels=6, num_filters=32, num_classes=5):\n        super().__init__()\n        \n        # --- Helper for Fusion ---\n        # Fuses 2 inputs of size 'ch' into 1 output of size 'ch'\n        def fuse_block(ch): \n            return nn.Conv2d(ch * 2, ch, kernel_size=1, bias=False)\n\n        # --- Encoders (Static & Dynamic) ---\n        # Assuming Encode returns (skip, downsampled)\n        # Level 1: 3 -> 32\n        self.enc_s1 = Encode(3, num_filters)\n        self.enc_d1 = Encode(3, num_filters)\n        self.fuse1 = fuse_block(num_filters)\n\n        # Level 2: 32 -> 64\n        self.enc_s2 = Encode(num_filters, num_filters * 2)\n        self.enc_d2 = Encode(num_filters, num_filters * 2)\n        self.fuse2 = fuse_block(num_filters * 2)\n\n        # Level 3: 64 -> 128\n        self.enc_s3 = Encode(num_filters * 2, num_filters * 4)\n        self.enc_d3 = Encode(num_filters * 2, num_filters * 4)\n        self.fuse3 = fuse_block(num_filters * 4)\n\n        # Level 4: 128 -> 256\n        self.enc_s4 = Encode(num_filters * 4, num_filters * 8)\n        self.enc_d4 = Encode(num_filters * 4, num_filters * 8)\n        self.fuse4 = fuse_block(num_filters * 8)\n\n        # --- The Bottleneck Fusion ---\n        # We must fuse the final *downsampled* outputs (xs, xd), not just the skips.\n        self.fuse_bottleneck = fuse_block(num_filters * 8)\n\n        # --- Bridge ---\n        # 256 -> 512 (Standard U-Net doubles channels at bridge)\n        self.bridge = DoubleConv(num_filters * 8, num_filters * 16)\n\n        # --- Decoder ---\n        # Note: Input channels = (Upsampled Input) + (Skip Connection)\n        \n        # Up 1: Input (Bridge 512) + Skip x4 (Fused 256) -> Output 256\n        self.up1 = Decode(num_filters * 16, num_filters * 8, num_filters * 8, (0, 0))\n        \n        # Up 2: Input (Up1 256) + Skip x3 (Fused 128) -> Output 128\n        self.up2 = Decode(num_filters * 8, num_filters * 4, num_filters * 4, (0, 1))\n        \n        # Up 3: Input (Up2 128) + Skip x2 (Fused 64) -> Output 64\n        self.up3 = Decode(num_filters * 4, num_filters * 2, num_filters * 2, (1, 0))\n        \n        # Up 4: Input (Up3 64) + Skip x1 (Fused 32) -> Output 64 (or 32 depending on preference)\n        self.up4 = Decode(num_filters * 2, num_filters, num_filters, (0, 1))\n\n        self.out_conv = nn.Conv2d(num_filters, num_classes, kernel_size=1)\n\n    def forward(self, x):\n        # 1. Split Input\n        xs_in = x[:, [0, 2, 4], :, :]\n        xd_in = x[:, [1, 3, 5], :, :]\n\n        # 2. Encoders\n        # Level 1\n        x1s, xs = self.enc_s1(xs_in)\n        x1d, xd = self.enc_d1(xd_in)\n        x1 = self.fuse1(torch.cat([x1s, x1d], dim=1)) # Fused Skip 1\n\n        # Level 2\n        x2s, xs = self.enc_s2(xs)\n        x2d, xd = self.enc_d2(xd)\n        x2 = self.fuse2(torch.cat([x2s, x2d], dim=1)) # Fused Skip 2\n\n        # Level 3\n        x3s, xs = self.enc_s3(xs)\n        x3d, xd = self.enc_d3(xd)\n        x3 = self.fuse3(torch.cat([x3s, x3d], dim=1)) # Fused Skip 3\n\n        # Level 4\n        x4s, xs = self.enc_s4(xs)\n        x4d, xd = self.enc_d4(xd)\n        x4 = self.fuse4(torch.cat([x4s, x4d], dim=1)) # Fused Skip 4\n\n        # 3. Bottleneck\n        # FIX: We now fuse the actual downsampled outputs (xs, xd)\n        x_bottleneck = self.fuse_bottleneck(torch.cat([xs, xd], dim=1))\n        \n        # 4. Bridge\n        x = self.bridge(x_bottleneck)\n\n        # 5. Decoder (Pass the fused skips)\n        x = self.up1(x, x4)\n        x = self.up2(x, x3)\n        x = self.up3(x, x2)\n        x = self.up4(x, x1)\n\n        return self.out_conv(x)","metadata":{"id":"08f1e82f-1a41-4caf-a135-54705222aaf6","trusted":true,"execution":{"iopub.status.busy":"2026-02-02T08:41:21.725291Z","iopub.execute_input":"2026-02-02T08:41:21.725484Z","iopub.status.idle":"2026-02-02T08:41:21.73874Z","shell.execute_reply.started":"2026-02-02T08:41:21.725466Z","shell.execute_reply":"2026-02-02T08:41:21.738122Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class GroupedStem(nn.Module):\n    def __init__(self, in_channels=6, out_channels=32, groups=3):\n        super().__init__()\n        mid = out_channels * groups\n        self.net = nn.Sequential(\n            nn.Conv2d(in_channels, mid, 3, padding=1, groups=groups, bias=False),\n            nn.BatchNorm2d(mid),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(mid, out_channels, 3, padding=1, bias=False),\n            nn.BatchNorm2d(out_channels),\n            nn.ReLU(inplace=True),\n        )\n    def forward(self, x):\n     return self.net(x)","metadata":{"id":"xxI0Ot1om8T8","trusted":true,"execution":{"iopub.status.busy":"2026-02-02T08:41:21.740307Z","iopub.execute_input":"2026-02-02T08:41:21.740521Z","iopub.status.idle":"2026-02-02T08:41:21.753269Z","shell.execute_reply.started":"2026-02-02T08:41:21.740502Z","shell.execute_reply":"2026-02-02T08:41:21.752755Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class TriNet(nn.Module):\n    def __init__(self, in_channels=6, num_filters=32, num_classes=5):\n        super().__init__()\n        self.stem = GroupedStem(in_channels, num_filters, groups=3)\n        \n        # --- Encoder ---\n        # 32 -> 64\n        self.down1 = Encode(num_filters, num_filters * 2) \n        # 64 -> 128\n        self.down2 = Encode(num_filters * 2, num_filters * 4)\n        # 128 -> 256\n        self.down3 = Encode(num_filters * 4, num_filters * 8)\n        \n        # --- Bridge ---\n        # 256 -> 512\n        self.bridge = DoubleConv(num_filters * 8, num_filters * 16)\n        \n        # --- Decoder ---\n        # Up 1: Input 512 (Bridge) + Skip 256 (x3) -> Output 256\n        self.up1 = Decode(num_filters * 16, num_filters * 8, num_filters * 8, (0, 1))\n        \n        # Up 2: Input 256 + Skip 128 (x2) -> Output 128\n        self.up2 = Decode(num_filters * 8, num_filters * 4, num_filters * 4, (1, 0))\n        \n        # Up 3: Input 128 + Skip 64 (x1) -> Output 32 (Matches num_filters)\n        self.up3 = Decode(num_filters * 4, num_filters * 2, num_filters, (0, 1))\n        \n        # --- Output ---\n        # Now accepts 32 channels, outputs 2 classes (logits)\n        self.out_conv = nn.Conv2d(num_filters, num_classes, 1)\n\n    def forward(self, x):\n        x0 = self.stem(x)         # H\n        x1, x = self.down1(x0)    # H/2 (x1 is H)\n        x2, x = self.down2(x)     # H/4\n        x3, x = self.down3(x)     # H/8\n        \n        x = self.bridge(x)        # H/8\n        \n        x = self.up1(x, x3)       # H/4\n        x = self.up2(x, x2)       # H/2\n        x = self.up3(x, x1)       # H (Matches x1 resolution)\n        \n        return self.out_conv(x)   # Output: (B, num_classes, H, W)","metadata":{"id":"WRtDt7hKoiWk","trusted":true,"execution":{"iopub.status.busy":"2026-02-02T08:41:21.75442Z","iopub.execute_input":"2026-02-02T08:41:21.754742Z","iopub.status.idle":"2026-02-02T08:41:21.767901Z","shell.execute_reply.started":"2026-02-02T08:41:21.75472Z","shell.execute_reply":"2026-02-02T08:41:21.767323Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class MegaEnsemble(nn.Module):\n    def __init__(self, num_filters=32, num_classes=5):\n        super().__init__()\n        self.tri = TriNet(num_filters=num_filters, num_classes=num_classes)\n        self.double_net = DuoUNet(num_filters=num_filters, num_classes=num_classes)\n\n    def forward(self, x):\n        out_tri = self.tri(x)        # logits from geometry-grouped\n        out_double = self.double_net(x)  # logits from modality-grouped\n        return (out_tri + out_double) / 2  # average logits","metadata":{"id":"uJwLeSlRnjon","trusted":true,"execution":{"iopub.status.busy":"2026-02-02T08:41:21.768799Z","iopub.execute_input":"2026-02-02T08:41:21.769105Z","iopub.status.idle":"2026-02-02T08:41:21.783755Z","shell.execute_reply.started":"2026-02-02T08:41:21.769085Z","shell.execute_reply":"2026-02-02T08:41:21.783212Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class_weights = torch.tensor([1.0, 50.0, 50.0, 50.0, 50.0]).to(device)\n\ndef train(model):\n\n    model.train()\n    model.to(device)\n\n    loss_fn = nn.CrossEntropyLoss(\n        reduction='mean',\n        weight = class_weights,\n    )\n\n    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n\n    warmup = 1\n    epochs = 19\n\n    main_sch = torch.optim.lr_scheduler.LinearLR(\n        optimizer, start_factor=1.0, end_factor=0.0,\n        total_iters=epochs * len(train_loader)\n    )\n\n    warmup_sch = torch.optim.lr_scheduler.LinearLR(\n        optimizer, start_factor=0.01, end_factor=1.0,\n        total_iters=warmup * len(train_loader)\n    )\n\n    scheduler = torch.optim.lr_scheduler.SequentialLR(\n        optimizer,\n        schedulers=[warmup_sch, main_sch],\n        milestones=[warmup * len(train_loader)]\n    )\n\n    scaler = torch.amp.GradScaler(device)\n\n    for epoch in range(warmup + epochs):\n        model.train()\n\n        running_loss = 0.0\n        weighted_correct_sum = 0.0\n        weight_sum = 0.0\n\n        for x, y in train_loader:\n            x, y = x.to(device), y.to(device)\n            y += 1\n\n            optimizer.zero_grad(set_to_none=True)\n\n            with torch.amp.autocast(device):\n                outputs = model(x)\n                loss = loss_fn(outputs, y)\n\n            scaler.scale(loss).backward()\n            scaler.step(optimizer)\n            scaler.update()\n            scheduler.step()\n\n            running_loss += loss.item()\n\n            # ---- FIXED WEIGHTED ACCURACY ----\n            preds = outputs.argmax(dim=1)\n            sample_weights = class_weights[y]\n            correct = (preds == y).float()\n\n            weighted_correct_sum += (correct * sample_weights).sum().item()\n            weight_sum += sample_weights.sum().item()\n\n        running_loss /= len(train_loader)\n        train_acc = 100.0 * weighted_correct_sum / weight_sum\n\n        print(f\"Epoch {epoch+1}\")\n        print(f\"Train Loss: {running_loss:.4f}\")\n        print(f\"Train Accuracy (weighted): {train_acc:.2f}\")\n\n    return model, running_loss","metadata":{"id":"10907972-e7ef-4d2a-80b2-20386976f626","trusted":true,"execution":{"iopub.status.busy":"2026-02-02T08:41:21.785248Z","iopub.execute_input":"2026-02-02T08:41:21.785672Z","iopub.status.idle":"2026-02-02T08:41:21.799822Z","shell.execute_reply.started":"2026-02-02T08:41:21.78565Z","shell.execute_reply":"2026-02-02T08:41:21.799171Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class MyModel(nn.Module):\n    def __init__(self):\n        super(MyModel, self).__init__()\n        self.models = nn.ModuleList(MegaEnsemble() for _ in range(5))\n\n    def forward(self, x):\n        return sum(model(x) for model in self.models) / len(self.models)","metadata":{"id":"2fec8b1b-5e9c-4693-9138-91e1d9e1889f","trusted":true,"execution":{"iopub.status.busy":"2026-02-02T08:41:21.800746Z","iopub.execute_input":"2026-02-02T08:41:21.800973Z","iopub.status.idle":"2026-02-02T08:41:21.817311Z","shell.execute_reply.started":"2026-02-02T08:41:21.800954Z","shell.execute_reply":"2026-02-02T08:41:21.816521Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = MyModel().to(device)\nmodel, loss = train(model)","metadata":{"id":"bU7sUfjkRopd","trusted":true,"execution":{"iopub.status.busy":"2026-02-02T08:41:21.818914Z","iopub.execute_input":"2026-02-02T08:41:21.819172Z","iopub.status.idle":"2026-02-02T09:08:46.944207Z","shell.execute_reply.started":"2026-02-02T08:41:21.819154Z","shell.execute_reply":"2026-02-02T09:08:46.943361Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class TestDataset(torch.utils.data.Dataset):\n    def __init__(self, file_paths):\n        self.file_paths = file_paths\n        self.static_idx = torch.tensor([0, 2, 4])\n        self.dynamic_idx = torch.tensor([1, 3, 5])\n\n    def __len__(self):\n        return len(self.file_paths)\n\n    def __getitem__(self, idx):\n        path = self.file_paths[idx]\n        data = torch.load(path)\n\n        imgs_in = data[:6].float()\n        static3 = imgs_in.index_select(0, self.static_idx)\n        dynamic3 = imgs_in.index_select(0, self.dynamic_idx)\n        images = torch.cat([static3, dynamic3], dim=0)\n\n        filename = os.path.basename(path)\n        return images, filename\n\n\n\ntest_file_paths = [\n    f\"{TEST_DATA_PATH}/{file}\"\n    for file in os.listdir(TEST_DATA_PATH)\n    if file.endswith(\".mat.pt\")\n]\n\ntest_dataset = TestDataset(file_paths=test_file_paths)\n\ntest_loader = torch.utils.data.DataLoader(\n    dataset=TestDataset(test_file_paths),\n    batch_size=8,\n    shuffle=False,\n    num_workers=2,\n    pin_memory=True\n)","metadata":{"id":"z7NGy1ooLxLw","trusted":true,"execution":{"iopub.status.busy":"2026-02-02T09:08:46.945662Z","iopub.execute_input":"2026-02-02T09:08:46.945936Z","iopub.status.idle":"2026-02-02T09:08:46.95454Z","shell.execute_reply.started":"2026-02-02T09:08:46.945905Z","shell.execute_reply":"2026-02-02T09:08:46.954017Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def run_inference(model, data_loader):\n    model.eval()\n    model.to(device)\n\n    predictions = []\n    filenames = []\n\n    with torch.no_grad():\n        for images, file_names in data_loader:\n            images = images.to(device)\n\n            outputs = model(images)\n\n            # shifted back: [0..4] â†’ [-1..3]\n            preds = outputs.argmax(dim=1) - 1\n\n            for i in range(len(preds)):\n                predictions.append(preds[i].cpu().numpy())\n                filenames.append(file_names[i])\n\n    return predictions, filenames","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-02T09:08:46.955337Z","iopub.execute_input":"2026-02-02T09:08:46.955537Z","iopub.status.idle":"2026-02-02T09:08:46.975637Z","shell.execute_reply.started":"2026-02-02T09:08:46.955518Z","shell.execute_reply":"2026-02-02T09:08:46.975076Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_predictions, test_filenames = run_inference(model, test_loader)\n\nrows = []\nfor fname, pred in zip(test_filenames, test_predictions):\n    row = {\"filename\": fname}\n    for i, p in enumerate(pred.flatten()):\n        row[f\"pixel_{i}\"] = p\n    rows.append(row)\n\nsubmission = pd.DataFrame(rows)\nsubmission.to_csv(\"final.csv\", index=False)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-02T09:33:05.825948Z","iopub.execute_input":"2026-02-02T09:33:05.826766Z","iopub.status.idle":"2026-02-02T09:33:38.308187Z","shell.execute_reply.started":"2026-02-02T09:33:05.826728Z","shell.execute_reply":"2026-02-02T09:33:38.307285Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}