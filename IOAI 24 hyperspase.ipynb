{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[]},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":14521522,"sourceType":"datasetVersion","datasetId":9274684},{"sourceId":14521606,"sourceType":"datasetVersion","datasetId":9274732}],"dockerImageVersionId":31259,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/shokhjahonisroilov/ioai-hyperspase?scriptVersionId=294163165\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"<img src=\"./figs/IOAI-Logo.png\" alt=\"IOAI Logo\" width=\"200\" height=\"auto\">\n\n[IOAI 2024 (Burgas, Bulgaria), On-Site Round](https://ioai-official.org/bulgaria-2024)\n\n[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/IOAI-official/IOAI-2024/blob/main/On-Site-Round/Lost_in_Hyperspace/Lost_in_Hyperspace.ipynb)","metadata":{}},{"cell_type":"markdown","source":"# Lost in a Hyperspace: ML Regression challenge\n\n<img src=\"./figs/Lost in Hyperspace Fig 1.png\" width=\"300\">","metadata":{"id":"4b8eIP3OA4lG"}},{"cell_type":"markdown","source":"## Story Background\nCongratulations on your promotion to Principal Engineering Detective! Your impressive work on the previous task has earned you this exciting new challenge.\nNow, you are entrusted with the ancient and mesmerizing Glowing Hypercubes, which share some intriguing characteristics with the \"Pulse of the Machine\" widgets from your last mission (refer to Important Tips for details).\nYour mission is to unravel the mysteries of these Glowing Hypercubes by predicting three vital properties using the provided data.\n## Objective and Limitations\n- Your ultimate goal is to effectively predicts three properties of the Glowing Hypercubes\n- Every Glowing Hypercube is represented by the (5 x 5 x 5 x 6) array with lots of symmetries and unique properties (see Important tips section for details)\n- You need to engineer a small number of features from the Glowing Hypercube data, since  efficient factory procedures allow you to **only use Linear Regression** as a model, with no hyperparameters change allowed. You are also limited by 300 features for each task.\n- Your success will be measured by Root Mean Square Error metric for each feature independently and is translated into the score on the leaderboard.\n- Note that different features have different weights in the final score. See `SCALING_WEIGHTS` variable for details. After scaling, to make a single score number, we will average normalized RMSEs for each property.\n- Your solution for each task should not exceed 5 minutes for feature generation, training, and inference on the standard Colab non-GPU instance.\n- Share the `ml_feature_0.txt`, `ml_feature_1.txt`, and `ml_feature_2.txt` files with us, and don't forget to supply your Google Colab as well","metadata":{"id":"K_dOtWuJB4Tl"}},{"cell_type":"markdown","source":"## Important Tips\n\n<img src=\"./figs/Lost in Hyperspace Fig 2.png\" width=\"600\">","metadata":{"id":"jz08H4tEm9Uv"}},{"cell_type":"markdown","source":"- Linear Regression documentation\n  - https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html\n\n- Handy Numpy functions:\n  - https://numpy.org/doc/stable/reference/generated/numpy.swapaxes.html\n  - https://numpy.org/doc/stable/reference/generated/numpy.ravel.html\n  - https://numpy.org/doc/stable/reference/generated/numpy.reshape.html\n\n- Root Mean Square Error\n  - https://en.wikipedia.org/wiki/Root_mean_square_deviation","metadata":{"id":"41T2-TwqnL4Z"}},{"cell_type":"markdown","source":"## Clarification of the methods' usage\n\nMethods' usage limitations mostly resemble the ones for the home task, namely:\n\n- Mind the time limits. These are separate for each forecasting model, and suggest non-GPU instance. This time includes feature generation, training, and inference on the validation/test set. Data analysis, feature search and selection are not subject to the time limitation\n\n- Supervised neural networks (and any supervised models: LDA, boosting trees, etc) are not allowed as a feature extractor. Usage of simpler supervised models (e.g., ensembles on trees, linear regression) for the feature selection is allowed, given the model not being used as a feature extractor. Unsupervised learning is allowed (including autoencoders).\n\n- Usage of pretrained models or auto ML solutions is not allowed. Libraries that automatically sort through various approaches (including unsupervised ones) for the users are not allowed as well.\n\n- Given the time constraints, Colab notebooks should be as reproducible as possible. In case of doubt (abuse of the time limits, data usage, etc), Jury have the right to use the models/answers generated by the notebook, and pick the answers with the lower score.\n\n- Yes, different models can use different feature sets.\n\n- No, you cannot use the validation data for training.\n\n**If you are not sure, please ask Jury!**","metadata":{"id":"Q0Qc6fuDiKLq"}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nimport matplotlib.pyplot as plt\n\nSCALING_WEIGHTS = [100/15, 100/8, 100/100]","metadata":{"id":"FHg2wwvMjbtq","trusted":true,"execution":{"iopub.status.busy":"2026-01-17T20:33:49.294489Z","iopub.execute_input":"2026-01-17T20:33:49.294768Z","iopub.status.idle":"2026-01-17T20:33:49.29916Z","shell.execute_reply.started":"2026-01-17T20:33:49.294743Z","shell.execute_reply":"2026-01-17T20:33:49.298268Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data = pd.read_pickle('/kaggle/input/input-data/ml_data_onsite_start.pickle')\nfor key in data.keys():\n  print(key)","metadata":{"id":"qAR3qYrho9jH","trusted":true,"execution":{"iopub.status.busy":"2026-01-17T20:33:49.309582Z","iopub.execute_input":"2026-01-17T20:33:49.310264Z","iopub.status.idle":"2026-01-17T20:33:49.328966Z","shell.execute_reply.started":"2026-01-17T20:33:49.310236Z","shell.execute_reply":"2026-01-17T20:33:49.328347Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for key in data['X'].keys():\n  print(key)","metadata":{"id":"CAEURZQXpGq7","trusted":true,"execution":{"iopub.status.busy":"2026-01-17T20:33:49.329943Z","iopub.execute_input":"2026-01-17T20:33:49.330208Z","iopub.status.idle":"2026-01-17T20:33:49.333959Z","shell.execute_reply.started":"2026-01-17T20:33:49.33012Z","shell.execute_reply":"2026-01-17T20:33:49.333195Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for key in data['y'].keys():\n  print(key)","metadata":{"id":"9H2JakugpJ6t","trusted":true,"execution":{"iopub.status.busy":"2026-01-17T20:33:49.335136Z","iopub.execute_input":"2026-01-17T20:33:49.335331Z","iopub.status.idle":"2026-01-17T20:33:49.350494Z","shell.execute_reply.started":"2026-01-17T20:33:49.335314Z","shell.execute_reply":"2026-01-17T20:33:49.349744Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_train = data['X']['train']\ny_train = data['y']['train']\n\nX_val = data['X']['val']\ny_val = data['y']['val']\n\nX_test = data['X']['live_test']","metadata":{"id":"yAxYNuBmpK0M","trusted":true,"execution":{"iopub.status.busy":"2026-01-17T20:33:49.351593Z","iopub.execute_input":"2026-01-17T20:33:49.351818Z","iopub.status.idle":"2026-01-17T20:33:49.3668Z","shell.execute_reply.started":"2026-01-17T20:33:49.351792Z","shell.execute_reply":"2026-01-17T20:33:49.365802Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_train.shape, y_train.shape, X_val.shape, y_val.shape, X_test.shape","metadata":{"id":"wOnsz-hRpa5-","trusted":true,"execution":{"iopub.status.busy":"2026-01-17T20:33:49.367834Z","iopub.execute_input":"2026-01-17T20:33:49.368123Z","iopub.status.idle":"2026-01-17T20:33:49.382903Z","shell.execute_reply.started":"2026-01-17T20:33:49.3681Z","shell.execute_reply":"2026-01-17T20:33:49.381913Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def vis(arr):\n  plt.figure(figsize=(8, 8))\n\n  cnt = 1\n  for z in range(5):\n    for q in range(6):\n      plt.subplot(5, 6, cnt)\n      plt.imshow(arr[:, :, z, q], vmin=-50, vmax=40, cmap='hsv')\n      plt.grid()\n      plt.axis('off')\n      cnt += 1\n  plt.tight_layout()","metadata":{"id":"FF3vFKAipdD9","trusted":true,"execution":{"iopub.status.busy":"2026-01-17T20:33:49.385294Z","iopub.execute_input":"2026-01-17T20:33:49.385565Z","iopub.status.idle":"2026-01-17T20:33:49.39859Z","shell.execute_reply.started":"2026-01-17T20:33:49.385543Z","shell.execute_reply":"2026-01-17T20:33:49.397767Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_train.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-17T20:33:49.399429Z","iopub.execute_input":"2026-01-17T20:33:49.399588Z","iopub.status.idle":"2026-01-17T20:33:49.414502Z","shell.execute_reply.started":"2026-01-17T20:33:49.399572Z","shell.execute_reply":"2026-01-17T20:33:49.413781Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"vis(X_train[11])","metadata":{"id":"x2mmIfNZqJvh","trusted":true,"execution":{"iopub.status.busy":"2026-01-17T20:33:49.415468Z","iopub.execute_input":"2026-01-17T20:33:49.415664Z","iopub.status.idle":"2026-01-17T20:33:49.764882Z","shell.execute_reply.started":"2026-01-17T20:33:49.415644Z","shell.execute_reply":"2026-01-17T20:33:49.763773Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Functions for result evaluation / writing predictions\n\nDo not change it!","metadata":{"id":"uqtuaDQnrMi-"}},{"cell_type":"code","source":"def test_solution(X_train, y_train, X_val, y_val, feature_num=0):\n    assert X_train.shape[-1] <= 300, \"Too many features! Should be less than 300\"\n    assert X_val.shape[-1] <= 300, \"Too many features! Should be less than 300\"\n\n    model =  LinearRegression().fit(\n        X_train,\n        y_train[:, feature_num]\n    )\n    predictions = model.predict(X_val)\n    rmse = mean_squared_error(\n        predictions,\n        y_val[:, feature_num]\n    )**.5\n    normalized_rmse = rmse * SCALING_WEIGHTS[feature_num]\n    print(f\"Property #{feature_num}:    raw RMSE={rmse:.6f}\")\n    print(f\"Property #{feature_num}: scaled RMSE={normalized_rmse:.6f}\")\n    return round(normalized_rmse, 6)","metadata":{"id":"tURADTwiqK8O","trusted":true,"execution":{"iopub.status.busy":"2026-01-17T20:33:49.766982Z","iopub.execute_input":"2026-01-17T20:33:49.767227Z","iopub.status.idle":"2026-01-17T20:33:49.772615Z","shell.execute_reply.started":"2026-01-17T20:33:49.767203Z","shell.execute_reply":"2026-01-17T20:33:49.771504Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Let's try a baseline solution","metadata":{"id":"U1isIq9era53"}},{"cell_type":"code","source":"def symmetrize_x(X_tr, y_tr):\n    xxx = [\n        X_tr,\n        X_tr.swapaxes(1, 2),\n        X_tr.swapaxes(1, 3),\n        X_tr.swapaxes(2, 3),\n        X_tr.swapaxes(1, 3).swapaxes(1, 2),\n        X_tr.swapaxes(1, 3).swapaxes(2, 3),\n    ]\n    return np.concatenate(xxx), np.vstack([y_tr]*6)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-17T20:33:49.773509Z","iopub.execute_input":"2026-01-17T20:33:49.773746Z","iopub.status.idle":"2026-01-17T20:33:49.788145Z","shell.execute_reply.started":"2026-01-17T20:33:49.773691Z","shell.execute_reply":"2026-01-17T20:33:49.787356Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def augment_rotations_xyz(X, y=None):\n\n    def rotate_xy(X, k):\n        return np.rot90(X, k=k, axes=(1, 2))\n\n    def rotate_xz(X, k):\n        return np.rot90(X, k=k, axes=(1, 3))\n\n    def rotate_xz(X, k):\n        return np.rot90(X, k=k, axes=(1, 3))\n\n    def rotate_yz(X, k):\n        return np.rot90(X, k=k, axes=(2, 3))\n\n    \n    X_aug = []\n    y_aug = []\n\n    for k in [0, 1, 2, 3]:\n        X1 = rotate_xy(X, k)\n        X_aug.append(X1)\n        if y is not None:\n            y_aug.append(y)\n\n        X2 = rotate_xz(X, k)\n        X_aug.append(X2)\n        if y is not None:\n            y_aug.append(y)\n\n        X3 = rotate_yz(X, k)\n        X_aug.append(X3)\n        if y is not None:\n            y_aug.append(y)\n\n    X_aug = np.concatenate(X_aug, axis=0)\n\n    if y is not None:\n        y_aug = np.concatenate(y_aug, axis=0)\n        return X_aug, y_aug\n\n    return X_aug\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-17T20:33:49.789478Z","iopub.execute_input":"2026-01-17T20:33:49.789813Z","iopub.status.idle":"2026-01-17T20:33:49.806571Z","shell.execute_reply.started":"2026-01-17T20:33:49.789788Z","shell.execute_reply":"2026-01-17T20:33:49.805753Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_train_symm, y_train_symm = symmetrize_x(X_train, y_train)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-17T20:33:49.807456Z","iopub.execute_input":"2026-01-17T20:33:49.807666Z","iopub.status.idle":"2026-01-17T20:33:49.849276Z","shell.execute_reply.started":"2026-01-17T20:33:49.807646Z","shell.execute_reply":"2026-01-17T20:33:49.848566Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_train_symm.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-17T20:33:49.850104Z","iopub.execute_input":"2026-01-17T20:33:49.850346Z","iopub.status.idle":"2026-01-17T20:33:49.855075Z","shell.execute_reply.started":"2026-01-17T20:33:49.850321Z","shell.execute_reply":"2026-01-17T20:33:49.854423Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def base(X):\n    X_new = X.reshape((X.shape[0], -1)) # ravel\n    X_new = X_new[:, :300] # pick first 300 features\n    return X_new","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-17T20:33:49.855826Z","iopub.execute_input":"2026-01-17T20:33:49.855981Z","iopub.status.idle":"2026-01-17T20:33:49.868519Z","shell.execute_reply.started":"2026-01-17T20:33:49.855965Z","shell.execute_reply":"2026-01-17T20:33:49.867783Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def get_diff(X):\n    bgs = []\n    for _x in X:\n        bg = _x[:,:,:,3].ravel().min() - _x[:,:,:,2].ravel().max()\n        bgs.append(bg)\n    bgs = np.array(bgs)\n\n    bgs2 = []\n    for x in X:\n        bg = x[:,:,:,5].ravel().min() - x[:,:,:,4].ravel().max()\n        bgs2.append(bg)\n    bgs2 = np.array(bgs2)\n    return np.concatenate([bgs[:, None], bgs2[:, None]], axis=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-17T20:33:49.87066Z","iopub.execute_input":"2026-01-17T20:33:49.870918Z","iopub.status.idle":"2026-01-17T20:33:49.884165Z","shell.execute_reply.started":"2026-01-17T20:33:49.870894Z","shell.execute_reply":"2026-01-17T20:33:49.883454Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\n\ndef ravelize(x):\n    return x.reshape(x.shape[0], -1)\n\npca = PCA(n_components=300-2-98-50-16)\nscaler = StandardScaler()\nX_tr_sc = scaler.fit_transform(ravelize(X_train_symm))\nX_val_sc= scaler.transform(ravelize(X_val))\nX_train_pca = pca.fit_transform(X_tr_sc)\nX_val_pca = pca.transform((X_val_sc))","metadata":{"id":"gxP4tDP2rXgQ","trusted":true,"execution":{"iopub.status.busy":"2026-01-17T20:33:49.88519Z","iopub.execute_input":"2026-01-17T20:33:49.885447Z","iopub.status.idle":"2026-01-17T20:33:50.182041Z","shell.execute_reply.started":"2026-01-17T20:33:49.88542Z","shell.execute_reply":"2026-01-17T20:33:50.181544Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_train_diff = get_diff(X_train_symm)\nX_val_diff = get_diff(X_val)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-17T20:33:50.182617Z","iopub.execute_input":"2026-01-17T20:33:50.182807Z","iopub.status.idle":"2026-01-17T20:33:50.371431Z","shell.execute_reply.started":"2026-01-17T20:33:50.182788Z","shell.execute_reply":"2026-01-17T20:33:50.370786Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.cluster import KMeans\n\nkmeans = KMeans(\n    n_clusters=98,\n    random_state=42,\n    n_init=10\n)\n\nX_tr_cluster = kmeans.fit_transform(X_tr_sc)\nX_val_cluster = kmeans.transform(X_val_sc)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-17T20:33:50.372175Z","iopub.execute_input":"2026-01-17T20:33:50.372394Z","iopub.status.idle":"2026-01-17T20:34:08.263146Z","shell.execute_reply.started":"2026-01-17T20:33:50.37237Z","shell.execute_reply":"2026-01-17T20:34:08.262643Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.decomposition import FastICA\n\nica = FastICA(\n    n_components=50,\n    random_state=42,\n    max_iter=1000,\n    whiten=\"unit-variance\"\n)\n\nX_train_ica = ica.fit_transform(X_tr_sc)\nX_val_ica   = ica.transform(X_val_sc)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-17T20:34:08.263684Z","iopub.execute_input":"2026-01-17T20:34:08.263867Z","iopub.status.idle":"2026-01-17T20:34:11.611952Z","shell.execute_reply.started":"2026-01-17T20:34:08.263848Z","shell.execute_reply":"2026-01-17T20:34:11.611435Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras import layers, Model\n\ninput_dim = ravelize(X_train_symm).shape[1]\nlatent_dim = 16\n\ninp = layers.Input(shape=(input_dim,))\nx = layers.Dense(128, activation=\"relu\")(inp)\nx = layers.Dense(64, activation=\"relu\")(x)\nlatent = layers.Dense(latent_dim, activation=\"linear\")(x)\n\nx = layers.Dense(64, activation=\"relu\")(latent)\nx = layers.Dense(128, activation=\"relu\")(x)\nout = layers.Dense(input_dim, activation=\"linear\")(x)\n\nautoencoder = Model(inp, out)\nencoder = Model(inp, latent)\n\nautoencoder.compile(\n    optimizer=\"adam\",\n    loss=\"mse\"\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-17T20:34:11.612744Z","iopub.execute_input":"2026-01-17T20:34:11.612914Z","iopub.status.idle":"2026-01-17T20:34:11.686801Z","shell.execute_reply.started":"2026-01-17T20:34:11.612895Z","shell.execute_reply":"2026-01-17T20:34:11.686276Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"autoencoder.fit(\n    ravelize(X_train_symm),\n    ravelize(X_train_symm),\n    validation_data=(ravelize(X_val), ravelize(X_val)),\n    epochs=50,\n    batch_size=64,\n    verbose=0\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-17T20:34:11.688909Z","iopub.execute_input":"2026-01-17T20:34:11.689094Z","iopub.status.idle":"2026-01-17T20:34:50.161625Z","shell.execute_reply.started":"2026-01-17T20:34:11.689074Z","shell.execute_reply":"2026-01-17T20:34:50.160942Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_tr_ae = encoder.predict(ravelize(X_train_symm))\nX_val_ae = encoder.predict(ravelize(X_val))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-17T20:34:50.162567Z","iopub.execute_input":"2026-01-17T20:34:50.162809Z","iopub.status.idle":"2026-01-17T20:34:50.793063Z","shell.execute_reply.started":"2026-01-17T20:34:50.162785Z","shell.execute_reply":"2026-01-17T20:34:50.792407Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_tr_comb = np.concatenate([X_train_pca, X_train_diff,X_tr_cluster, X_train_ica, X_tr_ae], axis=-1)\nX_val_comb = np.concatenate([X_val_pca, X_val_diff, X_val_cluster, X_val_ica, X_val_ae], axis=-1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-17T20:34:50.793887Z","iopub.execute_input":"2026-01-17T20:34:50.79407Z","iopub.status.idle":"2026-01-17T20:34:50.806717Z","shell.execute_reply.started":"2026-01-17T20:34:50.794053Z","shell.execute_reply":"2026-01-17T20:34:50.806026Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_val_comb.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-17T20:34:50.807543Z","iopub.execute_input":"2026-01-17T20:34:50.807778Z","iopub.status.idle":"2026-01-17T20:34:50.812965Z","shell.execute_reply.started":"2026-01-17T20:34:50.807754Z","shell.execute_reply":"2026-01-17T20:34:50.812272Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%time\ntotal_score = 0\nfor feature_number in range(3):\n  total_score += test_solution(\n      base(X_train),\n      y_train,\n      base(X_val),\n      y_val,\n      feature_num=feature_number\n  )\n  print()\ntotal_score /= 3\nprint('='*16)\nprint(f\"Total score = {total_score:.6f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-17T20:34:50.813747Z","iopub.execute_input":"2026-01-17T20:34:50.81395Z","iopub.status.idle":"2026-01-17T20:34:50.978572Z","shell.execute_reply.started":"2026-01-17T20:34:50.813933Z","shell.execute_reply":"2026-01-17T20:34:50.977994Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%time\ntotal_score = 0\nfor feature_number in range(3):\n  total_score += test_solution(\n      X_train_pca,\n      y_train_symm,\n      X_val_pca,\n      y_val,\n      feature_num=feature_number\n  )\n  print()\ntotal_score /= 3\nprint('='*16)\nprint(f\"Total score = {total_score:.6f}\")","metadata":{"id":"72XghC9lSZR9","trusted":true,"execution":{"iopub.status.busy":"2026-01-17T20:34:50.979399Z","iopub.execute_input":"2026-01-17T20:34:50.980557Z","iopub.status.idle":"2026-01-17T20:34:51.182207Z","shell.execute_reply.started":"2026-01-17T20:34:50.980534Z","shell.execute_reply":"2026-01-17T20:34:51.181522Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%time\ntotal_score = 0\nfor feature_number in range(3):\n  total_score += test_solution(\n      X_tr_comb,\n      y_train_symm,\n      X_val_comb,\n      y_val,\n      feature_num=feature_number\n  )\n  print()\ntotal_score /= 3\nprint('='*16)\nprint(f\"Total score = {total_score:.6f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-17T20:34:51.183944Z","iopub.execute_input":"2026-01-17T20:34:51.184159Z","iopub.status.idle":"2026-01-17T20:34:51.737213Z","shell.execute_reply.started":"2026-01-17T20:34:51.184139Z","shell.execute_reply":"2026-01-17T20:34:51.736766Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"****Best score : 1.433150****","metadata":{}},{"cell_type":"markdown","source":"## How to prepare the answer files","metadata":{"id":"FdwcTRrhxDfy"}},{"cell_type":"code","source":"# def generate_predictions(X_train, y_train, X_test, feature_num=0):\n#     assert X_train.shape[-1] <= 300\n#     assert X_test.shape[-1] <= 300\n\n#     model =  LinearRegression().fit(\n#         X_train,\n#         y_train[:, feature_num]\n#     )\n#     predictions = model.predict(X_test)\n#     return predictions\n\n\n# ## Generate solutions and write to the file\n# combined = {'ID': np.arange(X_test.shape[0])}\n\n# for feature_number in range(3):\n#     predictions = generate_predictions(\n#         dummy_feature_extractor(X_train),\n#         y_train,\n#         dummy_feature_extractor(X_test),\n#         feature_num=feature_number\n#     )\n\n#     combined[f'y{feature_number+1}'] = predictions\n\n# pd.DataFrame(combined).to_csv('predictions.csv', index=False)","metadata":{"id":"45q5BbihsA6j","trusted":true,"execution":{"iopub.status.busy":"2026-01-17T20:34:51.738151Z","iopub.execute_input":"2026-01-17T20:34:51.73834Z","iopub.status.idle":"2026-01-17T20:34:51.742499Z","shell.execute_reply.started":"2026-01-17T20:34:51.738321Z","shell.execute_reply":"2026-01-17T20:34:51.742048Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # load the test dataset\n# loaded = pd.read_pickle(\"/kaggle/input/test-data/ml_data_onsite_final_test.pickle\")\n# X_test_final = loaded['X']['final_test']\n\n\n# # make final predictions\n# combined = {'ID': np.arange(X_test_final.shape[0])}\n\n# for feature_number in range(3):\n#     predictions = generate_predictions(\n#         dummy_feature_extractor(X_train),\n#         y_train,\n#         dummy_feature_extractor(X_test_final),\n#         feature_num=feature_number\n#     )\n\n#     combined[f'y{feature_number+1}'] = predictions\n\n# pd.DataFrame(combined).to_csv('final_predictions.csv', index=False)","metadata":{"id":"W4TTqdR8ptan","trusted":true,"execution":{"iopub.status.busy":"2026-01-17T20:34:51.744038Z","iopub.execute_input":"2026-01-17T20:34:51.744216Z","iopub.status.idle":"2026-01-17T20:34:51.761125Z","shell.execute_reply.started":"2026-01-17T20:34:51.744197Z","shell.execute_reply":"2026-01-17T20:34:51.760605Z"}},"outputs":[],"execution_count":null}]}